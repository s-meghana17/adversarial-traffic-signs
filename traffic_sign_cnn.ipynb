{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22212c44-b0c1-4fbe-bb3b-3906f7a44c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1227s\u001b[0m 7us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 15ms/step - accuracy: 0.3857 - loss: 1.6988 - val_accuracy: 0.5519 - val_loss: 1.2710\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Clean       0.50      0.79      0.61       100\n",
      " Adversarial       0.50      0.21      0.30       100\n",
      "\n",
      "    accuracy                           0.50       200\n",
      "   macro avg       0.50      0.50      0.45       200\n",
      "weighted avg       0.50      0.50      0.45       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Load and preprocess dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Step 2: Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=1, validation_data=(x_test, y_test))  # Train quickly with 1 epoch\n",
    "\n",
    "# Step 3: Generate adversarial example using FGSM\n",
    "def generate_fgsm(model, image, label, epsilon=0.01):\n",
    "    image = tf.convert_to_tensor(image[None], dtype=tf.float32)\n",
    "    label = tf.convert_to_tensor(label[None])\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(label, prediction)\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    adv_image = image + epsilon * signed_grad\n",
    "    adv_image = tf.clip_by_value(adv_image, 0, 1)\n",
    "    return adv_image.numpy()[0]\n",
    "\n",
    "# Step 4: Extract statistical features\n",
    "def extract_stats(img):\n",
    "    return [np.mean(img), np.std(img), np.max(img), np.min(img)]\n",
    "\n",
    "# Step 5: Build dataset with clean and adversarial features\n",
    "features, true_labels = [], []\n",
    "for i in range(100):\n",
    "    clean_img = x_test[i]\n",
    "    label = y_test[i]\n",
    "\n",
    "    features.append(extract_stats(clean_img))\n",
    "    true_labels.append(0)  # Clean\n",
    "\n",
    "    adv_img = generate_fgsm(model, clean_img, label)\n",
    "    features.append(extract_stats(adv_img))\n",
    "    true_labels.append(1)  # Adversarial\n",
    "\n",
    "# Step 6: Train anomaly detector\n",
    "detector = IsolationForest()\n",
    "detector.fit(features)\n",
    "preds = detector.predict(features)\n",
    "preds = [1 if p == -1 else 0 for p in preds]  # convert: -1 → adversarial (1)\n",
    "\n",
    "# Step 7: Print classification results\n",
    "print(classification_report(true_labels, preds, target_names=[\"Clean\", \"Adversarial\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7efeb-8529-4487-89a2-feab05a60e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3134e03-8f5f-4abf-965f-0ee9fbb6a50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
